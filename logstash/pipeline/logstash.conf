input {
	beats {
		port => 5045
		tags => ["Beat"]
	}

	tcp {
		port => 5044
		codec => plain {charset => "UTF-8"}
	}
	
}

filter {
	# Categorize platform according to IP address
	# ITD
	# | IP         | Name | Description |
	# | ---------- | ---- | ----------- |
	# | 10.0.31.81 |      | On Prems    |
	# | 10.0.31.91 |      | On Prems    |
	# | 10.0.31.83 |      | On Prems    |
	# |            |      |             |

	# Phong tich hop, ebanking, platform = itd_ebanking_tichhop
	# + 100.69.45.5 (eskyone, web sso)
	# + 100.69.46.5 (eskyone, web sso)
	# + 100.69.31.97 (job ekyc)
	# + 100.69.3.9 (sso api)
	# + 100.69.35.9(sso api)
	# + 10.0.31.21
	# + 10.0.31.97
	# + 10.0.31.20

	if [@metadata][input][tcp][source][ip] in ["10.0.31.81","10.0.31.91","10.0.31.83"] {
		mutate {
			add_field => {"platform" => "itd"}
		}
	}
	# DTC
	if [@metadata][input][tcp][source][ip] in ["10.0.55.74","10.0.31.34","10.0.41.44","10.0.55.86"] {
	
		mutate {
			add_field => {"platform" => "dtc"}
		}	
	}
	# Beat log type
	if "Beat" in [tags] {
		# Cloud Service 
		# | IP          | Name             | Description  |
		# | 100.75.8.21 | keycloak-app-uat | Cloud Server |
		# |             |                  |              |
    
    	# Refs: https://www.elastic.co/guide/en/logstash/current/plugins-inputs-beats.html (This plugin currenly not using ECS
    	# but I just added the ECS anyway because maybe other developer will enable ECS.

		if [@metadata][input][beats][host][ip] or [@metadata][ip_address] in ["100.75.8.21"] {
			mutate {
				add_field => ["src_ip", "%{[@metadata][input][beats][host][ip]}"]	
				add_field => ["platform", "itd"]
			}
		# May require custom parse rule here later on
		} else {

			mutate {
				add_field => ["src_ip", "%{[@metadata][input][beats][host][ip]}"]	
		 		add_field => ["platform", "dtc"]
			}
		}
		
		# if [fields][type] == "log-dop" or "hdbs-cctg"{
		# 	grok {
		# 		match => {"message" => [""]}
		# 	}
		# }

		# Grok filter for Windows Server 10.0.55.74, 10.0.31.34
		# pattern for DTC logs (Windows Server using FileBeat) 
		grok {
			match => {"message" =>	["(?m)%{WORD:level}  %{TIMESTAMP_ISO8601:time} .* \[%{UUID:requestId}\] \[%{DATA:function}\]\[%{DATA:status}\]%{GREEDYDATA:message}",
			"(?m)%{WORD:level}%{SPACE}%{TIMESTAMP_ISO8601:time} .* \[%{NUMBER:number}\]%{SPACE}\[%{DATA:function}\]\[%{DATA:status}\]%{GREEDYDATA:message}",
			"(?m)%{WORD:level}%{SPACE}%{TIMESTAMP_ISO8601:time} .* \[%{UUID:requestId}\] %{DATA:function} \[{%DATA:status}\]%{SPACE}%{GREEDYDATA:message}",
			"(?m)%{WORD:level}%{SPACE}%{TIMESTAMP_ISO8601:time} %{DATA:execution_time} %{WORD:number} %{WORD:level}%{SPACE}\- %{DATA:function} \=\=\> %{DATA:status}: %{GREEDYDATA:message}",
			"\[%{TIMESTAMP_ISO8601:time}\] %{DATA:function} \- %{DATA:status}: %{WORD:level}: %{GREEDYDATA:message}",
			"\[%{TIMESTAMP_ISO8601:time}\] %{DATA:function} \- \[%{UUID:requestId}\]%{DATA:status}: %{WORD:level}%{SPACE}%{GREEDYDATA:message}",
			"\[%{TIMESTAMP_ISO8601:time}\] %{DATA:function} \- %{DATA:status}: %{GREEDYDATA:message}",
			"\[%{TIMESTAMP_ISO8601:time}\] %{DATA:function} \- %{DATA:status} %{GREEDYDATA:message}"]}
			overwrite => [ "message" ]
		}
	} else {
		# If not start with timestamp -> will become multiline
		multiline {
			pattern => "^%{TIMESTAMP_ISO8601} "
			negate => true
			what => "previous"
		}
		# multiline { 
		# 	pattern => "^\[" 
		# 	what => "previous"
		# 	negate => true
		# }
		mutate {
			add_field => ["src_ip","%{[@metadata][input][tcp][source][ip]}"]
			remove_field => [ "host" ]
		}
		
		grok {
			match => {"message" => ["(?m)\[%{TIMESTAMP_ISO8601:time}\] %{DATA:function}\ - \[(?<requestId>([a-f0-9]{8}(-[a-f0-9]{4}){4}[a-f0-9]{8}))\](?<status>(\[(.+)\])):%{GREEDYDATA:message}",
			"(?m)\[%{TIMESTAMP_ISO8601:time}\] %{DATA:function}\ - (?<status>(\[(.+)\]))(.+)(?<level>call) %{GREEDYDATA:message}",
			"(?m)\[%{TIMESTAMP_ISO8601:time}\] %{DATA:function}\ - (?<status>(\[(.*?)\])+)\W*(?<level>RESPONSE|Response|Error code|Pool Status|Recieved data|Input|OutPut|Output|resultCode|ResultCode|REQUEST)\:*%{GREEDYDATA:message}",
			"(?m)\[%{TIMESTAMP_ISO8601:time}\] %{DATA:function}\ - (?<status>\[(.*?)\])\W+%{WORD:level}(\:|\s+string\:) %{GREEDYDATA:message}",
			"(?m)\[%{TIMESTAMP_ISO8601:time}\] %{DATA:function}\ - (?<status>[^\:\s]*|\[(.*?)\])%{GREEDYDATA:message}"]}
			overwrite => [ "message" ]
		}
	}

	date {
		timezone => "Asia/Ho_Chi_Minh"
		match => [ "time", "ISO8601", "yyyy-MM-dd HH:mm:ss" ]
		target => "@timestamp"
		locale => "en"
	}
	# For further understading why I doing this https://www.elastic.co/guide/en/logstash/7.17/plugins-outputs-elasticsearch.html
	# Using one elasticsearch output is much more efficicent (the documentation said so)
	# @metadata usage: https://www.elastic.co/guide/en/logstash/7.17/event-dependent-configuration.html#metadata
}

output {
  # Setup elasticsearch for aws using load balancer
	if "itd" in [platform] {
		elasticsearch{
			# HTTPS stuff
			hosts => ["${ELASTIC_HOST}"]
			cacert => "/usr/share/logstash/config/certs/ca/ca.crt"
			ssl => true
			ecs_compatibility => disabled
			# Logstash user on Elastic
			user =>  "${LOGSTASH_USER}"
			password => "${LOGSTASH_PASSWORD}"
			codec => plain { charset=> "UTF-8" }
			index => "itd-%{+YYYY.MM.dd}"
		}
	}else if "dtc" in [platform]{
			elasticsearch{
			# HTTPS stuff
			hosts => ["${ELASTIC_HOST}"]
			cacert => "/usr/share/logstash/config/certs/ca/ca.crt"
			ssl => true
			ecs_compatibility => disabled
			# Logstash user on Elastic
			user =>  "${LOGSTASH_USER}"
			password => "${LOGSTASH_PASSWORD}"
			codec => plain { charset=> "UTF-8" }
			index => "dtc-%{+YYYY.MM.dd}"
		}
	} else {
		elasticsearch{
			# HTTPS stuff
			hosts => ["${ELASTIC_HOST}"]
			cacert => "/usr/share/logstash/config/certs/ca/ca.crt"
			ssl => true
			ecs_compatibility => disabled
			# Logstash user on Elastic
			user =>  "${LOGSTASH_USER}"
			password => "${LOGSTASH_PASSWORD}"
			codec => plain { charset=> "UTF-8" }
			index => "unknown-%{+YYYY.MM.dd}"
		}
	}
}
